import streamlit as st
import pandas as pd
import difflib
from difflib import SequenceMatcher
from kiwipiepy import Kiwi
import numpy as np

# í˜ì´ì§€ ì„¤ëª… ë¶€ë¶„
st.title("í•™êµìƒí™œê¸°ë¡ë¶€ ë…ì„œê¸°ë¡ ì¤‘ë³µ ì°¾ê¸°ğŸ“š")
st.write("ìƒí™œê¸°ë¡ë¶€ ì ê²€ì‹œ, í•™ìƒë§ˆë‹¤ ë…ì„œê¸°ë¡ì´ ì¤‘ë³µëœ ê²½ìš°ê°€ ì™•ì™• ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ í•œ í•™ìƒì´ 2í•™ë…„ 1í•™ê¸°ì™€ 1í•™ë…„ 1í•™ê¸°ì— ê°™ì€ ì±…ì„ ê¸°ë¡í•œ ê²½ìš°ì£ ! ë‚˜ì´ìŠ¤ì—ì„œ **ë°˜ë³„ ë…ì„œê¸°ë¡íŒŒì¼**ì„ csvíŒŒì¼ë¡œ ë‹¤ìš´ë°›ì•„, ì•„ë˜ì— ì—…ë¡œë“œí•´ì£¼ì„¸ìš”. ì¤‘ë³µëœ í•­ëª©ì´ ì¶œë ¥ë©ë‹ˆë‹¤. ")

def preprocessing(df):
    st.write(df)
    df = df.iloc[3:, :6]
    df.columns = ["name", "section", "year", "grade", "sem", "book"]  # column ì´ë¦„ ì§€ì •
    df = df.dropna(how='all')  # ëª¨ë“  ì¹¸ì´ nanì¸ í–‰ ì§€ìš°ê¸°
    df = df.fillna(method='ffill')  # í–‰ë³„ë¡œ ì´ë¦„ ì±„ìš°ê¸°(ì „ í–‰ì˜ ì´ë¦„ê³¼ ë™ì¼í•˜ê²Œ)
    df.drop(df[df['name'] =='ì´  ë¦„'].index, inplace=True)  # í˜ì´ì§€ ë„˜ì–´ê°ˆ ë•Œ ìˆëŠ” ì—´ì´ë¦„ ì¤‘ë³µë˜ë¯€ë¡œ ì‚­ì œ
    original = df.values.tolist()  # listë¡œ
    pd.options.display.max_colwidth = 100
    return df

def find_duplicate_books(df):
    # ì¤‘ë³µëœ ë¶€ë¶„ ì°¾ê¸° (1) ì±…ì´ë¦„ê³¼ ì €ìëª…ì´ ì™„ë²½íˆ ì¼ì¹˜
    for student in df.name.unique():
        # í•™ìƒë³„ë¡œ ë„ì„œëª… ë¬¸ìì—´ë¡œ ë‹´ê¸°
        temp = df[df.name == student]
        all_book = temp.book.tolist()
        book_list_incomplete = []
        for book_by_row in all_book:
            book_list_incomplete = book_list_incomplete + book_by_row.split("), ")

        # ë¹ˆ ë¬¸ìì—´ ì›ì†Œ ì œê±° ë° ê´„í˜¸ ì²˜ë¦¬í•˜ê¸°
        book_list = []
        for book in book_list_incomplete:
            if len(book) == 0:
                continue
            elif book[-1] == ")":
                book_list.append(book)
            else:
                book_list.append(book + ")")

        # ì¤‘ë³µ íšŸìˆ˜ ì„¸ê¸°
        book_count = {}
        lists = book_list
        for i in lists:
            try:
                book_count[i] += 1
            except:
                book_count[i] = 1

        # ì¤‘ë³µ íšŸìˆ˜ê°€ 2 ì´ìƒì¸ ì•„ì´í…œì˜ keyë§Œ ë‹´ê¸°
        book_duplicated = []
        for k, v in book_count.items():
            if v >= 2:
                book_duplicated.append(k)

        # ì¶œë ¥í•˜ê¸°
        if len(book_duplicated) > 0:
            for book in book_duplicated:
                st.write('\n', student, "í•™ìƒì˜ ë…ì„œê¸°ë¡ ì¤‘ **", book, "**ì´ ì¤‘ë³µë˜ì—ˆìŠµë‹ˆë‹¤.")
            for i in range(len(book_duplicated)):
                st.write(temp[temp['book'].str.contains(book_duplicated[i][:2])])
        else:
            continue

def find_duplicate_books_2(df, cut_off):
    kiwi = Kiwi()
    for student in df.name.unique():
        # í•™ìƒë³„ë¡œ ë„ì„œëª… ë¬¸ìì—´ë¡œ ë‹´ê¸°
        temp = df[df.name == student]
        all_book = temp.book.tolist()
        book_list_incomplete = []
        for book_by_row in all_book:
            book_list_incomplete = book_list_incomplete + book_by_row.split("), ")

        # ë¹ˆ ë¬¸ìì—´ ì›ì†Œ ì œê±° ë° ê´„í˜¸ ì²˜ë¦¬í•˜ê¸°
        book_list = []
        for book in book_list_incomplete:
            if len(book) == 0:
                continue
            elif book[-1] == ")":
                book_list.append(book)
            else:
                book_list.append(book + ")")

        for i in range(len(book_list)):
            for j in range(i+1, len(book_list)):
                similarity = get_similarity(book_list[i], book_list[j], kiwi)
                if similarity == 2:
                    st.write('#### ğŸ˜± {} í•™ìƒì˜ ì¤‘ë³µëœ ë…ì„œê¸°ë¡ì…ë‹ˆë‹¤.'.format(student))
                    st.write('ğŸ“™', book_list[i], 'ğŸ“—', book_list[j])
                    st.write(temp[temp['book'].str.contains(book_list[i][:5])].iloc[:,1:])
                elif similarity >= cut_off:
                    st.write('#### {} í•™ìƒì˜ ë¹„ìŠ·í•œ ë…ì„œê¸°ë¡ì…ë‹ˆë‹¤. ìœ ì‚¬ë„:{}'.format(student, np.round(similarity, 2)))
                    st.write('ğŸ“™', book_list[i], 'ğŸ“—', book_list[j])
                    st.write(temp[temp['book'].str.contains(book_list[i][:5])].iloc[:,1:])
                    st.write(temp[temp['book'].str.contains(book_list[j][:5])].iloc[:,1:])
                




def get_similarity(str1, str2, kiwi):
    tokens1 = kiwi.analyze(str1)[0][0]
    tokens2 = kiwi.analyze(str2)[0][0]

    morphemes1 = [token[0] for token in tokens1]
    morphemes2 = [token[0] for token in tokens2]

    list_sum = len(morphemes1+morphemes2)
    set_sum = len(set(morphemes1+morphemes2))
    similarity = list_sum/set_sum
    return similarity

cut_off_percent = st.slider("ì¡°ì ˆí•  ìˆ«ì", min_value=50, max_value=100, step=10, value = 100 )
cut_off = cut_off_percent*0.014+0.6 # 100ì´ë©´ 2ë¡œ, 50ì´ë©´ ì•½ 1.3ì •ë„ë¡œ


if 'book_record' not in st.session_state:
    st.session_state['book_record'] = ''

sample_book = pd.read_csv('https://raw.githubusercontent.com/Surihub/RPA/main/data/book_recording_sample.csv')


sample_checked = st.checkbox('ìƒ˜í”Œ íŒŒì¼ ì¤‘ë³µ ê¸°ì¬ í™•ì¸í•˜ê¸°')
if sample_checked:
    with st.spinner('ì¤‘ë³µì„ í™•ì¸í•˜ëŠ” ì¤‘ ì…ë‹ˆë‹¤...'):
        find_duplicate_books_2(preprocessing(sample_book), cut_off)


book_record = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”! ì¤€ë¹„ëœ íŒŒì¼ì´ ì—†ì„ ê²½ìš°, ìœ„ì˜ 'ìƒ˜í”Œ íŒŒì¼ ì—…ë¡œë“œ í•´ë³´ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.", type="csv")
if book_record:
    book_record = pd.read_csv(book_record)
    st.session_state['book_record'] = book_record

upload_checked = st.checkbox('ì—…ë¡œë“œí•œ íŒŒì¼ ì¤‘ë³µ ê¸°ì¬ í™•ì¸í•˜ê¸°!')
if upload_checked:
    with st.spinner('ì¤‘ë³µì„ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
        try:
            find_duplicate_books_2(preprocessing(st.session_state['book_record']), cut_off)
        except:
            st.write("âš ì˜¬ë°”ë¥¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì…¨ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”!")
