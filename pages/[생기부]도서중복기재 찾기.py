import streamlit as st
import pandas as pd
import numpy as np
from kiwipiepy import Kiwi

# í˜ì´ì§€ ì„¤ëª… ë¶€ë¶„
st.title("ğŸ“ší•™ìƒë¶€ ë…ì„œê¸°ë¡ ì¤‘ë³µ ì°¾ê¸°")

st.info('###### ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”?\nìƒí™œê¸°ë¡ë¶€ ì ê²€ì‹œ, í•™ìƒë§ˆë‹¤ ë…ì„œê¸°ë¡ì´ ì¤‘ë³µëœ ê²½ìš°ê°€ ì™•ì™• ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ í•œ í•™ìƒì´ 2í•™ë…„ 1í•™ê¸°ì™€ 1í•™ë…„ 1í•™ê¸°ì— ê°™ì€ ì±…ì„ ê¸°ë¡í•œ ê²½ìš°ì£ ! ë‚˜ì´ìŠ¤ì—ì„œ **ë°˜ë³„ ë…ì„œê¸°ë¡íŒŒì¼**ì„ csvíŒŒì¼ë¡œ ë‹¤ìš´ë°›ì•„, ì•„ë˜ì— ì—…ë¡œë“œí•´ì£¼ì„¸ìš”. ìœ ì‚¬ë„ì— ë”°ë¼ ì¤‘ë³µë˜ê±°ë‚˜ ë¹„ìŠ·í•œ í˜•íƒœì†Œë¡œ ì´ë¤„ì§„ ë‘ ë„ì„œê°€ ì¶œë ¥ë©ë‹ˆë‹¤.')
st.warning('###### ì–´ë–»ê²Œ í•´ê²°í•˜ë‚˜ìš”?\në…ì„œê¸°ë¡.csv â¡ ì¤‘ë³µëœ í•­ëª© ì¶œë ¥')

         
def preprocessing(df):
    st.write(df)
    df = df.iloc[3:, :6]
    df.columns = ["name", "section", "year", "grade", "sem", "book"]  # column ì´ë¦„ ì§€ì •
    df = df.dropna(how='all')  # ëª¨ë“  ì¹¸ì´ nanì¸ í–‰ ì§€ìš°ê¸°
    df = df.fillna(method='ffill')  # í–‰ë³„ë¡œ ì´ë¦„ ì±„ìš°ê¸°(ì „ í–‰ì˜ ì´ë¦„ê³¼ ë™ì¼í•˜ê²Œ)
    df.drop(df[df['name'] =='ì´  ë¦„'].index, inplace=True)  # í˜ì´ì§€ ë„˜ì–´ê°ˆ ë•Œ ìˆëŠ” ì—´ì´ë¦„ ì¤‘ë³µë˜ë¯€ë¡œ ì‚­ì œ
    original = df.values.tolist()  # listë¡œ
    pd.options.display.max_colwidth = 100
    return df

def find_duplicate_books_2(df, cut_off):
    kiwi = Kiwi()
    for student in df.name.unique():
        # í•™ìƒë³„ë¡œ ë„ì„œëª… ë¬¸ìì—´ë¡œ ë‹´ê¸°
        temp = df[df.name == student]
        all_book = temp.book.tolist()
        book_list_incomplete = []
        for book_by_row in all_book:
            book_list_incomplete = book_list_incomplete + book_by_row.split("), ")

        # ë¹ˆ ë¬¸ìì—´ ì›ì†Œ ì œê±° ë° ê´„í˜¸ ì²˜ë¦¬í•˜ê¸°
        book_list = []
        for book in book_list_incomplete:
            if len(book) == 0:
                continue
            elif book[-1] == ")":
                book_list.append(book)
            else:
                book_list.append(book + ")")

        for i in range(len(book_list)):
            for j in range(i+1, len(book_list)):
                similarity, morphs = get_similarity(book_list[i], book_list[j], kiwi)
                if similarity == 2:
                    st.write('#### ğŸ˜± {} í•™ìƒì˜ ì¤‘ë³µëœ ë…ì„œê¸°ë¡ì…ë‹ˆë‹¤.'.format(student))
                    st.write('ğŸ“™', book_list[i], 'ğŸ“—', book_list[j])
                    st.write(temp[temp['book'].str.contains(book_list[i][:5])].iloc[:,1:])
                elif similarity >= cut_off:
                    st.write('#### {} í•™ìƒì˜ ë¹„ìŠ·í•œ ë…ì„œê¸°ë¡ì…ë‹ˆë‹¤. ìœ ì‚¬ë„:{}'.format(student, np.round(similarity, 2)))
                    # st.write(morphs)#########
                    st.write('ğŸ“™', book_list[i], 'ğŸ“—', book_list[j])
                    st.write(temp[temp['book'].str.contains(book_list[i][:5])].iloc[:,1:])
                    st.write(temp[temp['book'].str.contains(book_list[j][:5])].iloc[:,1:])

def get_similarity(str1, str2, kiwi):
    # ë¬¸ìì—´ì„ Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜•íƒœì†Œë¡œ ë¶„ì„
    tokens1 = kiwi.analyze(str1)[0][0]
    tokens2 = kiwi.analyze(str2)[0][0]

    # í˜•íƒœì†Œë“¤ì„ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
    morphemes1 = [token[0] for token in tokens1]
    morphemes2 = [token[0] for token in tokens2]
    morphemes1.remove('(')
    morphemes1.remove(')')
    morphemes2.remove('(')
    morphemes2.remove(')')
    morphs = [morphemes1, morphemes2]

    # ë‘ ë¦¬ìŠ¤íŠ¸ì˜ ê¸¸ì´ì˜ í•©ê³¼ ì¤‘ë³µì„ ì œì™¸í•œ ìš”ì†Œì˜ ê°œìˆ˜ë¥¼ ê³„ì‚°
    list_sum = len(morphemes1 + morphemes2)
    set_sum = len(set(morphemes1 + morphemes2))

    # ìœ ì‚¬ë„ ê³„ì‚° (ë‘ ë¦¬ìŠ¤íŠ¸ì˜ ê¸¸ì´ì˜ í•©ì„ ì¤‘ë³µì„ ì œì™¸í•œ ìš”ì†Œì˜ ê°œìˆ˜ë¡œ ë‚˜ëˆ”)
    similarity = list_sum / set_sum

    # ìœ ì‚¬ë„ ë°˜í™˜
    return similarity, morphs

cut_off_percent = st.slider("ìœ ì‚¬ë„(%)ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”. ìœ ì‚¬ë„ê°€ 100ì¸ ê²½ìš° ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” ë„ì„œê°€ ì¶œë ¥ë©ë‹ˆë‹¤.", min_value=50, max_value=100, step=10, value = 100 )
cut_off = cut_off_percent*0.014+0.6 # 100ì´ë©´ 2ë¡œ, 50ì´ë©´ ì•½ 1.3ì •ë„ë¡œ

if 'book_record' not in st.session_state:
    st.session_state['book_record'] = ''

sample_book = pd.read_csv('https://raw.githubusercontent.com/Surihub/RPA/main/data/book_recording_sample.csv')


sample_checked = st.checkbox('ìƒ˜í”Œ íŒŒì¼ ì¤‘ë³µ ê¸°ì¬ í™•ì¸í•˜ê¸°')
if sample_checked:
    with st.spinner('ì¤‘ë³µì„ í™•ì¸í•˜ëŠ” ì¤‘ ì…ë‹ˆë‹¤...'):
        find_duplicate_books_2(preprocessing(sample_book), cut_off)


book_record = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”! ì¤€ë¹„ëœ íŒŒì¼ì´ ì—†ì„ ê²½ìš°, ìœ„ì˜ 'ìƒ˜í”Œ íŒŒì¼ ì—…ë¡œë“œ í•´ë³´ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.", type="csv")
if book_record:
    book_record = pd.read_csv(book_record)
    st.session_state['book_record'] = book_record

upload_checked = st.checkbox('ì—…ë¡œë“œí•œ íŒŒì¼ ì¤‘ë³µ ê¸°ì¬ í™•ì¸í•˜ê¸°!')
if upload_checked:
    with st.spinner('ì¤‘ë³µì„ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
        try:
            find_duplicate_books_2(preprocessing(st.session_state['book_record']), cut_off)
        except:
            st.write("âš ì˜¬ë°”ë¥¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì…¨ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”!")
